{
    "path": "backend/tools.py",
    "model_usage_metrics": {
        "Duration": 11784765011,
        "OpenAiUsage": {
            "completion_tokens": 0,
            "prompt_tokens": 0,
            "total_tokens": 0,
            "completion_tokens_details": {
                "accepted_prediction_tokens": 0,
                "audio_tokens": 0,
                "reasoning_tokens": 0,
                "rejected_prediction_tokens": 0
            },
            "prompt_tokens_details": {
                "audio_tokens": 0,
                "cached_tokens": 0
            }
        }
    },
    "test_file_path": "backend/test_tools.py",
    "existing_test_code": "",
    "original_code": "from typing import Literal\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain import hub\nfrom langchain_core.output_parsers import StrOutputParser\n\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain_community.tools.tavily_search import TavilySearchResults\nfrom pydantic import BaseModel, Field\n### from langchain_cohere import CohereEmbeddings\n\n\n\n# create index ########################################################################################################\n### Build Index\nfrom langchain_core.vectorstores import VectorStoreRetriever;\n\ndef build_index() -\u003e VectorStoreRetriever:\n\n    # Set embeddings\n    embd = OpenAIEmbeddings()\n\n    # Docs to index\n    urls = [\n        \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n        \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n        \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n    ]\n\n    # Load\n    docs = [WebBaseLoader(url).load() for url in urls]\n    docs_list = [item for sublist in docs for item in sublist]\n\n    # Split\n    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n        chunk_size=500, chunk_overlap=0\n    )\n    doc_splits = text_splitter.split_documents(docs_list)\n\n    # Add to vectorstore\n    vectorstore = Chroma.from_documents(\n        documents=doc_splits,\n        collection_name=\"rag-chroma\",\n        embedding=embd,\n    )\n    return vectorstore.as_retriever()\n\nretriever = build_index()\n\n\n# LLMs ###################################################################################################################\n\ndef build_question_router():\n    # Data model\n    class RouteQuery(BaseModel):\n        \"\"\"Route a user query to the most relevant datasource.\"\"\"\n\n        datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n            ...,\n            description=\"Given a user question choose to route it to web search or a vectorstore.\",\n        )\n\n\n    # LLM with function call\n    llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n    structured_llm_router = llm.with_structured_output(RouteQuery)\n\n    # Prompt\n    system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n    The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n    Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n    route_prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", system),\n            (\"human\", \"{question}\"),\n        ]\n    )\n\n    question_router = route_prompt | structured_llm_router\n    # print(\n    #     question_router.invoke(\n    #         {\"question\": \"Who will the Bears draft first in the NFL draft?\"}\n    #     )\n    # )\n    # print(question_router.invoke({\"question\": \"What are the types of agent memory?\"}))\n    return question_router\n\nquestion_router = build_question_router()\n\n### Retrieval Grader ##################################################################################################\ndef build_retrieval_grader():\n\n    # Data model\n    class GradeDocuments(BaseModel):\n        \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n\n        binary_score: str = Field(\n            description=\"Documents are relevant to the question, 'yes' or 'no'\"\n        )\n\n\n    # LLM with function call\n    llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n    structured_llm_grader = llm.with_structured_output(GradeDocuments)\n\n    # Prompt\n    system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n    grade_prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", system),\n            (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n        ]\n    )\n\n    retrieval_grader = grade_prompt | structured_llm_grader\n    \n    return retrieval_grader\n\nretrieval_grader = build_retrieval_grader()\n\n# question = \"agent memory\"\n# docs = retriever.invoke(question)\n# doc_txt = docs[1].page_content\n# print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))\n    \n\n### Generate ##########################################################################################################\ndef build_rag_chain():\n    # Prompt\n    prompt = hub.pull(\"rlm/rag-prompt\")\n\n    # LLM\n    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n\n\n    # Post-processing\n    def format_docs(docs):\n        return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\n    # Chain\n    rag_chain = prompt | llm | StrOutputParser()\n    return rag_chain\n\nrag_chain = build_rag_chain()\n# # Run\n# generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n# print(generation)\n\n### Hallucination Grader ################################################################################################\n\ndef build_hallucination_grader():\n    # Data model\n    class GradeHallucinations(BaseModel):\n        \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n\n        binary_score: str = Field(\n            description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n        )\n\n\n    # LLM with function call\n    llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n    structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n\n    # Prompt\n    system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n        Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n    hallucination_prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", system),\n            (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n        ]\n    )\n\n    hallucination_grader = hallucination_prompt | structured_llm_grader\n    return hallucination_grader\n\nhallucination_grader = build_hallucination_grader()\n#hallucination = hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})\n#print(hallucination)\n## GradeHallucinations(binary_score='yes')\n\n### Answer Grader ######################################################################################################\ndef build_answer_grader():\n\n    # Data model\n    class GradeAnswer(BaseModel):\n        \"\"\"Binary score to assess answer addresses question.\"\"\"\n\n        binary_score: str = Field(\n            description=\"Answer addresses the question, 'yes' or 'no'\"\n        )\n\n\n    # LLM with function call\n    llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n    structured_llm_grader = llm.with_structured_output(GradeAnswer)\n\n    # Prompt\n    system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n        Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n    answer_prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", system),\n            (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n        ]\n    )\n\n    answer_grader = answer_prompt | structured_llm_grader\n    return answer_grader\n\nanswer_grader = build_answer_grader()\n#answer_grader.invoke({\"question\": question, \"generation\": generation})\n\n## GradeAnswer(binary_score='yes')\n\n### Question Re-writer ################################################################################################\ndef build_question_rewriter():\n    # LLM\n    llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n\n    # Prompt\n    system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n        for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n    re_write_prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", system),\n            (\n                \"human\",\n                \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n            ),\n        ]\n    )\n\n    question_rewriter = re_write_prompt | llm | StrOutputParser()\n    return question_rewriter\n\nquestion_rewriter = build_question_rewriter()\n#question_rewriter.invoke({\"question\": question})\n\n## \"What is the role of memory in an agent's functioning?\"\n\n### Search #############################################################################################################\n\nweb_search_tool = TavilySearchResults(k=3)\n",
    "test_code": "import pytest\nfrom backend.tools import build_index, build_question_router, build_retrieval_grader, build_hallucination_grader, build_answer_grader, build_question_rewriter\n\nclass TestTools:\n\n    def test_build_index(self):\n        \"\"\"Test the build_index function to ensure it returns a VectorStoreRetriever.\"\"\"\n        # Step 1: Call the build_index function\n        retriever = build_index()\n        # Step 2: Assert that the returned object is an instance of VectorStoreRetriever\n        assert isinstance(retriever, VectorStoreRetriever)\n\n    def test_build_question_router(self):\n        \"\"\"Test the build_question_router function to ensure it returns a valid routing mechanism.\"\"\"\n        # Step 1: Call the build_question_router function\n        router = build_question_router()\n        # Step 2: Assert that the router can be invoked with a question\n        response = router.invoke({\"question\": \"What is agent memory?\"})\n        # Step 3: Assert that the response contains a valid datasource\n        assert response['datasource'] in [\"vectorstore\", \"web_search\"]\n\n    def test_build_retrieval_grader(self):\n        \"\"\"Test the build_retrieval_grader function to ensure it returns a valid grader.\"\"\"\n        # Step 1: Call the build_retrieval_grader function\n        grader = build_retrieval_grader()\n        # Step 2: Assert that the grader can be invoked with a document and question\n        response = grader.invoke({\"document\": \"This is a test document.\", \"question\": \"Is this relevant?\"})\n        # Step 3: Assert that the response is either 'yes' or 'no'\n        assert response['binary_score'] in ['yes', 'no']\n\n    def test_build_hallucination_grader(self):\n        \"\"\"Test the build_hallucination_grader function to ensure it returns a valid hallucination grader.\"\"\"\n        # Step 1: Call the build_hallucination_grader function\n        grader = build_hallucination_grader()\n        # Step 2: Assert that the grader can be invoked with documents and generation\n        response = grader.invoke({\"documents\": \"Fact 1. Fact 2.\", \"generation\": \"This is a generated answer.\"})\n        # Step 3: Assert that the response is either 'yes' or 'no'\n        assert response['binary_score'] in ['yes', 'no']\n\n    def test_build_answer_grader(self):\n        \"\"\"Test the build_answer_grader function to ensure it returns a valid answer grader.\"\"\"\n        # Step 1: Call the build_answer_grader function\n        grader = build_answer_grader()\n        # Step 2: Assert that the grader can be invoked with a question and generation\n        response = grader.invoke({\"question\": \"What is the capital of France?\", \"generation\": \"The capital of France is Paris.\"})\n        # Step 3: Assert that the response is either 'yes' or 'no'\n        assert response['binary_score'] in ['yes', 'no']\n\n    def test_build_question_rewriter(self):\n        \"\"\"Test the build_question_rewriter function to ensure it returns a valid question rewriter.\"\"\"\n        # Step 1: Call the build_question_rewriter function\n        rewriter = build_question_rewriter()\n        # Step 2: Assert that the rewriter can be invoked with a question\n        response = rewriter.invoke({\"question\": \"What is the role of memory in an agent's functioning?\"})\n        # Step 3: Assert that the response is a string (the rewritten question)\n        assert isinstance(response, str)\n",
    "amount_of_generated_test_cases": 6,
    "single_test_run_command": "pytest backend/test_tools.py"
}