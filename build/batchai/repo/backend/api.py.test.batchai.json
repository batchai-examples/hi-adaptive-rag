{
    "path": "backend/api.py",
    "model_usage_metrics": {
        "Duration": 11403662026,
        "OpenAiUsage": {
            "completion_tokens": 0,
            "prompt_tokens": 0,
            "total_tokens": 0,
            "completion_tokens_details": {
                "accepted_prediction_tokens": 0,
                "audio_tokens": 0,
                "reasoning_tokens": 0,
                "rejected_prediction_tokens": 0
            },
            "prompt_tokens_details": {
                "audio_tokens": 0,
                "cached_tokens": 0
            }
        }
    },
    "test_file_path": "backend/test_api.py",
    "existing_test_code": "",
    "original_code": "from datetime import datetime, timezone\nimport http\nimport os\nfrom logging import Logger\nfrom pprint import pprint\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import JSONResponse\nfrom starlette.middleware.base import BaseHTTPMiddleware\nfrom pydantic import BaseModel\n\nfrom dotenv import load_dotenv\nfrom misc import format_datetime\nfrom errs import BaseError\nfrom log import get_logger\nfrom workflow import workflow\n\nload_dotenv(dotenv_path=os.path.join(os.getcwd(), \".env\"))\n\n# Compile\ncompiled_workflow = workflow.compile()\n\n\nclass LoggingMiddleware(BaseHTTPMiddleware):\n    logger: Logger = get_logger(\"api\")\n\n    async def dispatch(self, request, call_next):\n        self.logger.info(\"Request body: %s\", await request.body())\n        resp = await call_next(request)\n        return resp\n    \n\nfastapi_app = FastAPI(validate_responses=False)\nfastapi_app.add_middleware(LoggingMiddleware)\n\n@fastapi_app.exception_handler(BaseError)\nasync def custom_exception_handler(request: Request, exc: BaseError):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"path\": request.url.path,\n            \"timestamp\": format_datetime(datetime.now(timezone.utc)),\n            \"status\": exc.status_code,\n            \"error\": http.HTTPStatus(exc.status_code).phrase,\n            \"code\": exc.code,\n            \"message\": exc.detail,\n            \"params\": [],\n        },\n    )\n\n\n@fastapi_app.exception_handler(500)\nasync def internal_exception_handler(request: Request, exc):\n    if isinstance(exc, BaseError):\n        return await custom_exception_handler(request, exc)\n    return JSONResponse(status_code=exc.status_code, content={\"detail\": exc.detail})\n\n \n\n\n####################################################################\nclass QuestionRequest(BaseModel):\n    question: str\n\nclass AnswerResponse(BaseModel):\n    question: str\n    answer: str\n\n@fastapi_app.post(\"/rest/v1/question\", response_model=AnswerResponse)\nasync def submit_question(request: QuestionRequest):\n    question = request.question.strip()\n    inputs = {\n        \"question\": question\n    }\n\n    for output in compiled_workflow.stream(inputs):\n        for key, value in output.items():\n            # Node\n            pprint(f\"Node '{key}':\")\n            # Optional: print full state at each node\n            # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n        pprint(\"\\n---\\n\")\n    \n    answer = value[\"generation\"]#\"Sorry, I don't know the answer to that question.\"\n    return {\"question\": question, \"answer\": answer}\n",
    "test_code": "import pytest\nfrom fastapi.testclient import TestClient\nfrom backend.api import fastapi_app\nfrom pydantic import ValidationError\n\nclient = TestClient(fastapi_app)\n\n# Test cases for the FastAPI application\n\ndef test_submit_question_happy_path():\n    \"\"\"\n    Test the /rest/v1/question endpoint with a valid question.\n    This represents a happy path scenario where the input is valid.\n    \"\"\"\n    response = client.post(\"/rest/v1/question\", json={\"question\": \"What is the capital of France?\"})\n    assert response.status_code == 200\n    assert response.json()[\"question\"] == \"What is the capital of France?\"\n    assert \"answer\" in response.json()\n\ndef test_submit_question_with_empty_string():\n    \"\"\"\n    Test the /rest/v1/question endpoint with an empty question.\n    This tests the validation of the input, expecting a 422 Unprocessable Entity response.\n    \"\"\"\n    response = client.post(\"/rest/v1/question\", json={\"question\": \"\"})\n    assert response.status_code == 422\n    assert \"detail\" in response.json()\n\ndef test_submit_question_with_whitespace():\n    \"\"\"\n    Test the /rest/v1/question endpoint with a question that is only whitespace.\n    This tests the validation of the input, expecting a 422 Unprocessable Entity response.\n    \"\"\"\n    response = client.post(\"/rest/v1/question\", json={\"question\": \"   \"})\n    assert response.status_code == 422\n    assert \"detail\" in response.json()\n\ndef test_submit_question_with_invalid_data_type():\n    \"\"\"\n    Test the /rest/v1/question endpoint with an invalid data type for the question.\n    This tests the validation of the input, expecting a 422 Unprocessable Entity response.\n    \"\"\"\n    response = client.post(\"/rest/v1/question\", json={\"question\": 12345})\n    assert response.status_code == 422\n    assert \"detail\" in response.json()\n\ndef test_submit_question_internal_server_error():\n    \"\"\"\n    Test the /rest/v1/question endpoint to simulate an internal server error.\n    This tests the error handling of the application.\n    \"\"\"\n    # Assuming we can trigger an internal error by sending a specific question\n    response = client.post(\"/rest/v1/question\", json={\"question\": \"Trigger internal error\"})\n    assert response.status_code == 500\n    assert \"detail\" in response.json()\n\ndef test_submit_question_with_special_characters():\n    \"\"\"\n    Test the /rest/v1/question endpoint with a question containing special characters.\n    This tests the application's ability to handle various characters in the input.\n    \"\"\"\n    response = client.post(\"/rest/v1/question\", json={\"question\": \"What is 2 + 2?\"})\n    assert response.status_code == 200\n    assert response.json()[\"question\"] == \"What is 2 + 2?\"\n    assert \"answer\" in response.json()\n",
    "amount_of_generated_test_cases": 6,
    "single_test_run_command": "pytest backend/test_api.py"
}