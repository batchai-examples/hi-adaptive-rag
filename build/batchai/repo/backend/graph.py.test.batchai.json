{
    "path": "backend/graph.py",
    "model_usage_metrics": {
        "Duration": 12155552098,
        "OpenAiUsage": {
            "completion_tokens": 0,
            "prompt_tokens": 0,
            "total_tokens": 0,
            "completion_tokens_details": {
                "accepted_prediction_tokens": 0,
                "audio_tokens": 0,
                "reasoning_tokens": 0,
                "rejected_prediction_tokens": 0
            },
            "prompt_tokens_details": {
                "audio_tokens": 0,
                "cached_tokens": 0
            }
        }
    },
    "test_file_path": "backend/test_graph.py",
    "existing_test_code": "",
    "original_code": "## Construct the Graph ################################################################################################\nfrom pprint import pprint\nfrom langchain.schema import Document\n\n### from langchain_cohere import CohereEmbeddings\n\nfrom typing import List\n\nfrom typing_extensions import TypedDict\nfrom tools import question_router, retriever, rag_chain, hallucination_grader, answer_grader, question_rewriter, web_search_tool, retrieval_grader\n\n\n\n\n### Define Graph State #################################################################################################\n\nclass GraphState(TypedDict):\n    \"\"\"\n    Represents the state of our graph.\n\n    Attributes:\n        question: question\n        generation: LLM generation\n        documents: list of documents\n    \"\"\"\n\n    question: str\n    generation: str\n    documents: List[str]\n\n### Define Graph Flow ##################################################################################################\n\ndef retrieve(state):\n    \"\"\"\n    Retrieve documents\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        state (dict): New key added to state, documents, that contains retrieved documents\n    \"\"\"\n    print(\"---RETRIEVE---\")\n    question = state[\"question\"]\n\n    # Retrieval\n    documents = retriever.invoke(question)\n    return {\"documents\": documents, \"question\": question}\n\n\ndef generate(state):\n    \"\"\"\n    Generate answer\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        state (dict): New key added to state, generation, that contains LLM generation\n    \"\"\"\n    print(\"---GENERATE---\")\n    question = state[\"question\"]\n    documents = state[\"documents\"]\n\n    # RAG generation\n    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n\n\ndef grade_documents(state):\n    \"\"\"\n    Determines whether the retrieved documents are relevant to the question.\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        state (dict): Updates documents key with only filtered relevant documents\n    \"\"\"\n\n    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n    question = state[\"question\"]\n    documents = state[\"documents\"]\n\n    # Score each doc\n    filtered_docs = []\n    for d in documents:\n        score = retrieval_grader.invoke(\n            {\"question\": question, \"document\": d.page_content}\n        )\n        grade = score.binary_score\n        if grade == \"yes\":\n            print(\"---GRADE: DOCUMENT RELEVANT---\")\n            filtered_docs.append(d)\n        else:\n            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n            continue\n    return {\"documents\": filtered_docs, \"question\": question}\n\n\ndef transform_query(state):\n    \"\"\"\n    Transform the query to produce a better question.\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        state (dict): Updates question key with a re-phrased question\n    \"\"\"\n\n    print(\"---TRANSFORM QUERY---\")\n    question = state[\"question\"]\n    documents = state[\"documents\"]\n\n    # Re-write question\n    better_question = question_rewriter.invoke({\"question\": question})\n    return {\"documents\": documents, \"question\": better_question}\n\n\ndef web_search(state):\n    \"\"\"\n    Web search based on the re-phrased question.\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        state (dict): Updates documents key with appended web results\n    \"\"\"\n\n    print(\"---WEB SEARCH---\")\n    question = state[\"question\"]\n\n    # Web search\n    docs = web_search_tool.invoke({\"query\": question})\n    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n    web_results = Document(page_content=web_results)\n\n    return {\"documents\": web_results, \"question\": question}\n\n\n### Edges ###\n\n\ndef route_question(state):\n    \"\"\"\n    Route question to web search or RAG.\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        str: Next node to call\n    \"\"\"\n\n    print(\"---ROUTE QUESTION---\")\n    question = state[\"question\"]\n    source = question_router.invoke({\"question\": question})\n    if source.datasource == \"web_search\":\n        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n        return \"web_search\"\n    elif source.datasource == \"vectorstore\":\n        print(\"---ROUTE QUESTION TO RAG---\")\n        return \"vectorstore\"\n\n\ndef decide_to_generate(state):\n    \"\"\"\n    Determines whether to generate an answer, or re-generate a question.\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        str: Binary decision for next node to call\n    \"\"\"\n\n    print(\"---ASSESS GRADED DOCUMENTS---\")\n    state[\"question\"]\n    filtered_documents = state[\"documents\"]\n\n    if not filtered_documents:\n        # All documents have been filtered check_relevance\n        # We will re-generate a new query\n        print(\n            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n        )\n        return \"transform_query\"\n    else:\n        # We have relevant documents, so generate answer\n        print(\"---DECISION: GENERATE---\")\n        return \"generate\"\n\n\ndef grade_generation_v_documents_and_question(state):\n    \"\"\"\n    Determines whether the generation is grounded in the document and answers question.\n\n    Args:\n        state (dict): The current graph state\n\n    Returns:\n        str: Decision for next node to call\n    \"\"\"\n\n    print(\"---CHECK HALLUCINATIONS---\")\n    question = state[\"question\"]\n    documents = state[\"documents\"]\n    generation = state[\"generation\"]\n\n    score = hallucination_grader.invoke(\n        {\"documents\": documents, \"generation\": generation}\n    )\n    grade = score.binary_score\n\n    # Check hallucination\n    if grade == \"yes\":\n        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n        # Check question-answering\n        print(\"---GRADE GENERATION vs QUESTION---\")\n        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n        grade = score.binary_score\n        if grade == \"yes\":\n            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n            return \"useful\"\n        else:\n            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n            return \"not useful\"\n    else:\n        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n        return \"not supported\"\n",
    "test_code": "import pytest\nfrom backend.graph import retrieve, generate, grade_documents, transform_query, web_search, route_question, decide_to_generate, grade_generation_v_documents_and_question\n\n# Sample state for testing\nsample_state = {\n    \"question\": \"What is the capital of France?\",\n    \"documents\": []\n}\n\n# Test cases for the graph functions\nclass TestGraphFunctions:\n    \n    def test_retrieve(self):\n        \"\"\"\n        Test the retrieve function with a valid question.\n        \"\"\"\n        # Given a sample state with a question\n        state = {\"question\": \"What is the capital of France?\"}\n        \n        # When we call retrieve\n        result = retrieve(state)\n        \n        # Then we should get documents related to the question\n        assert \"documents\" in result\n        assert isinstance(result[\"documents\"], list)\n\n    def test_generate(self):\n        \"\"\"\n        Test the generate function with valid state.\n        \"\"\"\n        # Given a sample state with documents\n        state = {\n            \"question\": \"What is the capital of France?\",\n            \"documents\": [\"Paris is the capital of France.\"]\n        }\n        \n        # When we call generate\n        result = generate(state)\n        \n        # Then we should get a generation in the result\n        assert \"generation\" in result\n        assert isinstance(result[\"generation\"], str)\n\n    def test_grade_documents_relevant(self):\n        \"\"\"\n        Test the grade_documents function with relevant documents.\n        \"\"\"\n        # Given a sample state with relevant documents\n        state = {\n            \"question\": \"What is the capital of France?\",\n            \"documents\": [{\"page_content\": \"Paris is the capital of France.\"}]\n        }\n        \n        # When we call grade_documents\n        result = grade_documents(state)\n        \n        # Then we should get filtered relevant documents\n        assert len(result[\"documents\"]) \u003e 0\n\n    def test_transform_query(self):\n        \"\"\"\n        Test the transform_query function to rephrase a question.\n        \"\"\"\n        # Given a sample state\n        state = {\n            \"question\": \"What is the capital of France?\",\n            \"documents\": []\n        }\n        \n        # When we call transform_query\n        result = transform_query(state)\n        \n        # Then we should get a better question\n        assert \"question\" in result\n        assert result[\"question\"] != state[\"question\"]\n\n    def test_route_question_web_search(self):\n        \"\"\"\n        Test the route_question function to route to web search.\n        \"\"\"\n        # Given a sample state\n        state = {\n            \"question\": \"What is the capital of France?\",\n            \"documents\": []\n        }\n        \n        # When we call route_question\n        result = route_question(state)\n        \n        # Then we should route to web_search\n        assert result == \"web_search\"\n\n    def test_decide_to_generate_no_relevant_docs(self):\n        \"\"\"\n        Test the decide_to_generate function when there are no relevant documents.\n        \"\"\"\n        # Given a sample state with no relevant documents\n        state = {\n            \"question\": \"What is the capital of France?\",\n            \"documents\": []\n        }\n        \n        # When we call decide_to_generate\n        result = decide_to_generate(state)\n        \n        # Then we should decide to transform the query\n        assert result == \"transform_query\"\n\n    def test_grade_generation_v_documents_and_question(self):\n        \"\"\"\n        Test the grade_generation_v_documents_and_question function.\n        \"\"\"\n        # Given a sample state with generation and documents\n        state = {\n            \"question\": \"What is the capital of France?\",\n            \"documents\": [\"Paris is the capital of France.\"],\n            \"generation\": \"The capital of France is Paris.\"\n        }\n        \n        # When we call grade_generation_v_documents_and_question\n        result = grade_generation_v_documents_and_question(state)\n        \n        # Then we should get a decision based on the grading\n        assert result in [\"useful\", \"not useful\", \"not supported\"]\n",
    "amount_of_generated_test_cases": 6,
    "single_test_run_command": "pytest backend/test_graph.py"
}